{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\ndef process_img_path(img_path):\n    return image.load_img(img_path, target_size=(224, 224))","metadata":{"execution":{"iopub.status.busy":"2022-04-19T19:36:01.608258Z","iopub.execute_input":"2022-04-19T19:36:01.609008Z","iopub.status.idle":"2022-04-19T19:36:01.613902Z","shell.execute_reply.started":"2022-04-19T19:36:01.608964Z","shell.execute_reply":"2022-04-19T19:36:01.613259Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"data = []\nfor i in ['phoenix', 'boston', 'saopaolo', 'tokyo', 'trondheim']:\n    for file in os.listdir('../input/smalldatanew/smallData/train/'+i):\n#         print(file) #to check if right files...\n        if file[-3:] == 'jpg':\n            path = os.path.join(f'./data/{i}/' + file)\n            img = process_img_path(path)\n            x = image.img_to_array(img)\n            \n            data.append(x)\n#             print(x)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T19:35:59.078955Z","iopub.execute_input":"2022-04-19T19:35:59.079415Z","iopub.status.idle":"2022-04-19T19:35:59.113046Z","shell.execute_reply.started":"2022-04-19T19:35:59.079364Z","shell.execute_reply":"2022-04-19T19:35:59.112059Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#imports\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.models import Sequential, Model\n#instantiate resnet50 & sew own a head -- input layer shape \nres = ResNet50(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\n# sew my tail on this beast\nx1 = res.output\nx1 = GlobalAveragePooling2D()(x1)\npredictions = Dense(y_train[0].shape[0], activation='softmax')(x1)\nmodel = Model(res.input, predictions)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.resnet50 import ResNet50\nfrom keras.applications.densenet import decode_predictions\nfrom keras.applications.densenet import preprocess_input\n\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nimport keras.preprocessing.image\n\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-04-19T19:36:24.074326Z","iopub.execute_input":"2022-04-19T19:36:24.074785Z","iopub.status.idle":"2022-04-19T19:36:24.081434Z","shell.execute_reply.started":"2022-04-19T19:36:24.074750Z","shell.execute_reply":"2022-04-19T19:36:24.080609Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# Basic Convolution","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras import backend as K","metadata":{"execution":{"iopub.status.busy":"2022-04-19T19:36:26.506862Z","iopub.execute_input":"2022-04-19T19:36:26.507444Z","iopub.status.idle":"2022-04-19T19:36:26.515651Z","shell.execute_reply.started":"2022-04-19T19:36:26.507402Z","shell.execute_reply":"2022-04-19T19:36:26.514887Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"img_width, img_height = 640, 480\n\ntrain_data_dir = '../input/smalldatanew/smallData/train'\nvalidation_data_dir = '../input/smalldatanew/smallData/validation'\nnb_train_samples = 1000\nnb_validation_samples = 250\nepochs = 10\nbatch_size = 16","metadata":{"execution":{"iopub.status.busy":"2022-04-19T19:36:27.670233Z","iopub.execute_input":"2022-04-19T19:36:27.670828Z","iopub.status.idle":"2022-04-19T19:36:27.675082Z","shell.execute_reply.started":"2022-04-19T19:36:27.670788Z","shell.execute_reply":"2022-04-19T19:36:27.674357Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"if K.image_data_format() == 'channels_first':\n    input_shape = (3, img_width, img_height)\nelse:\n    input_shape = (img_width, img_height, 3)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T19:36:28.787436Z","iopub.execute_input":"2022-04-19T19:36:28.788022Z","iopub.status.idle":"2022-04-19T19:36:28.793406Z","shell.execute_reply.started":"2022-04-19T19:36:28.787964Z","shell.execute_reply":"2022-04-19T19:36:28.791681Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(10))","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:44:15.472625Z","iopub.execute_input":"2022-04-19T15:44:15.472885Z","iopub.status.idle":"2022-04-19T15:44:15.525929Z","shell.execute_reply.started":"2022-04-19T15:44:15.472856Z","shell.execute_reply":"2022-04-19T15:44:15.525278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:44:15.599676Z","iopub.execute_input":"2022-04-19T15:44:15.599883Z","iopub.status.idle":"2022-04-19T15:44:15.610168Z","shell.execute_reply.started":"2022-04-19T15:44:15.599858Z","shell.execute_reply":"2022-04-19T15:44:15.609322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\n# this is the augmentation configuration we will use for training\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:44:15.742906Z","iopub.execute_input":"2022-04-19T15:44:15.743183Z","iopub.status.idle":"2022-04-19T15:44:15.754076Z","shell.execute_reply.started":"2022-04-19T15:44:15.743154Z","shell.execute_reply":"2022-04-19T15:44:15.753272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# this is the augmentation configuration we will use for testing:\n# only rescaling\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='binary')\n\nmodel.fit_generator(\n    train_generator,\n    steps_per_epoch=nb_train_samples // batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=nb_validation_samples // batch_size)\n\nmodel.save_weights('first_try.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:44:16.764971Z","iopub.execute_input":"2022-04-19T15:44:16.765224Z","iopub.status.idle":"2022-04-19T15:57:35.00919Z","shell.execute_reply.started":"2022-04-19T15:44:16.765195Z","shell.execute_reply":"2022-04-19T15:57:35.008401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transfer Learning","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport PIL\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2022-04-19T19:23:22.549116Z","iopub.execute_input":"2022-04-19T19:23:22.549382Z","iopub.status.idle":"2022-04-19T19:23:22.556726Z","shell.execute_reply.started":"2022-04-19T19:23:22.549353Z","shell.execute_reply":"2022-04-19T19:23:22.555979Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/smalldatanew/smallData/train'\nimg_height, img_width=224,224\nbatch_size=32\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T19:36:36.910052Z","iopub.execute_input":"2022-04-19T19:36:36.910757Z","iopub.status.idle":"2022-04-19T19:36:38.533727Z","shell.execute_reply.started":"2022-04-19T19:36:36.910722Z","shell.execute_reply":"2022-04-19T19:36:38.533039Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T19:36:40.689761Z","iopub.execute_input":"2022-04-19T19:36:40.690467Z","iopub.status.idle":"2022-04-19T19:36:41.539679Z","shell.execute_reply.started":"2022-04-19T19:36:40.690428Z","shell.execute_reply":"2022-04-19T19:36:41.538682Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(6):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-04-19T19:27:21.469600Z","iopub.execute_input":"2022-04-19T19:27:21.470366Z","iopub.status.idle":"2022-04-19T19:27:22.403350Z","shell.execute_reply.started":"2022-04-19T19:27:21.470316Z","shell.execute_reply":"2022-04-19T19:27:22.402328Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"resnet_model = Sequential()\n\npretrained_model= tf.keras.applications.ResNet50(include_top=False,\n                   input_shape=(224, 224, 3),\n                   pooling='avg',classes=5,\n                   weights='imagenet')\nfor layer in pretrained_model.layers:\n        layer.trainable=False\n\nresnet_model.add(pretrained_model)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T19:36:45.652472Z","iopub.execute_input":"2022-04-19T19:36:45.654192Z","iopub.status.idle":"2022-04-19T19:36:47.512391Z","shell.execute_reply.started":"2022-04-19T19:36:45.654135Z","shell.execute_reply":"2022-04-19T19:36:47.511652Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"resnet_model.add(Flatten())\nresnet_model.add(Dense(512, activation='relu'))\nresnet_model.add(Dense(5, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-04-19T19:36:48.153053Z","iopub.execute_input":"2022-04-19T19:36:48.153791Z","iopub.status.idle":"2022-04-19T19:36:48.178025Z","shell.execute_reply.started":"2022-04-19T19:36:48.153757Z","shell.execute_reply":"2022-04-19T19:36:48.177324Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"resnet_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T19:28:47.790480Z","iopub.execute_input":"2022-04-19T19:28:47.790742Z","iopub.status.idle":"2022-04-19T19:28:47.810210Z","shell.execute_reply.started":"2022-04-19T19:28:47.790713Z","shell.execute_reply":"2022-04-19T19:28:47.809515Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"resnet_model.compile(optimizer=Adam(lr=0.001), loss=\"sparse_categorical_crossentropy\"\n, metrics=['accuracy'])\n\nhistory = resnet_model.fit(train_ds, validation_data=val_ds, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T19:51:14.440583Z","iopub.execute_input":"2022-04-19T19:51:14.440848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig1 = plt.gcf()\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.axis(ymin=0.4,ymax=1)\nplt.grid()\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'validation'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T19:41:09.351872Z","iopub.execute_input":"2022-04-19T19:41:09.352565Z","iopub.status.idle":"2022-04-19T19:41:09.541565Z","shell.execute_reply.started":"2022-04-19T19:41:09.352526Z","shell.execute_reply":"2022-04-19T19:41:09.540849Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# DOESN'T WORK\n\nimport cv2\nimg_path = '../input/tokyotest/tokyotokyo.jpg'\ntest = keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n\npred=resnet_model.predict(image)\n\noutput_class=class_names[np.argmax(pred)]\nprint(\"The predicted class is\", output_class)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T19:49:00.324717Z","iopub.execute_input":"2022-04-19T19:49:00.324977Z","iopub.status.idle":"2022-04-19T19:49:00.357463Z","shell.execute_reply.started":"2022-04-19T19:49:00.324948Z","shell.execute_reply":"2022-04-19T19:49:00.355436Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-04-19T19:50:32.765123Z","iopub.execute_input":"2022-04-19T19:50:32.765693Z","iopub.status.idle":"2022-04-19T19:50:32.774628Z","shell.execute_reply.started":"2022-04-19T19:50:32.765638Z","shell.execute_reply":"2022-04-19T19:50:32.773816Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"try:\n    path=os.path.join(mypath, n)\n    img=cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    img=cv2.resize(img, (img_rows, img_cols))\n\nexcept Exception as e:\n    print(str(e))","metadata":{},"execution_count":null,"outputs":[]}]}