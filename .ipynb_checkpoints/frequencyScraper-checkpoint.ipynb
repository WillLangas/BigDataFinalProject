{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Reddit Comment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from praw.models import MoreComments\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=\"p1dG7hgoowK4BSlUdar1WQ\",\n",
    "    client_secret=\"pEePtSnw7KMDZi6fCzkKaOth_pgKpQ\",\n",
    "    password=\"outdoortuesday\",\n",
    "    user_agent=\"Big Data by u/DISWillJayminMaya \",\n",
    "    username=\"DISWillJayminMaya \",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def returnListofScores(listofcomments):\n",
    "    templist=[]\n",
    "    for com in listofcomments:\n",
    "        temp = analyzer.polarity_scores(com)\n",
    "        compScore = temp['compound']\n",
    "        templist.append(compScore)\n",
    "    return templist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickerlist = ['GME', 'Gamestop', 'SPY', 'TWTTR', 'Twitter', 'TSLA', 'Tesla', 'AMD']\n",
    "subreddit = reddit.subreddit('wallstreetbets')\n",
    "\n",
    "scoreDict={key:list() for key in tickerlist}\n",
    "\n",
    "hot = subreddit.hot(limit=25) # getting first 15 posts in the 'hot' section of the subreddit\n",
    "sum = [0] * len(tickerlist) # our output array\n",
    "counttotal = 0 # total number of comment read\n",
    "submissions_counter = 0\n",
    "\n",
    "rel_comments = [] # List of comments that are relevant to the ticker list items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'returnCompScore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16416/4024818855.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m                         \u001b[0mrel_comments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                         \u001b[0msum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                         \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturnCompScore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                         \u001b[0mscoreDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'returnCompScore' is not defined"
     ]
    }
   ],
   "source": [
    "# Loop for fetching the comments and the amount of time each ticker is mentioned\n",
    "for submissions in hot:\n",
    "    if not submissions.stickied:\n",
    "        submissions_counter+=1\n",
    "        if submissions_counter > 5:\n",
    "            comments = submissions.comments\n",
    "            for comment in comments:\n",
    "                if isinstance(comment, MoreComments):\n",
    "                    continue\n",
    "                counttotal+=1\n",
    "                for i, ticker in enumerate(tickerlist):\n",
    "                    if ticker in comment.body:\n",
    "                        rel_comments.append(comment.body)\n",
    "                        sum[i]=sum[i]+1\n",
    "                        temp = returnCompScore(comment.body)\n",
    "                        scoreDict[ticker].append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanDict={key:list() for key in tickerlist}\n",
    "spreadDict={key:list() for key in tickerlist}\n",
    "\n",
    "for tick in tickerlist:\n",
    "    if len(scoreDict[tick])>0:\n",
    "        meanDict[tick]=statistics.mean(scoreDict[tick])\n",
    "    if len (scoreDict[tick])>1:\n",
    "        spreadDict[tick]=statistics.stdev(scoreDict[tick])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GME': [], 'Gamestop': [], 'SPY': [], 'TWTTR': [], 'Twitter': [], 'TSLA': [], 'Tesla': [], 'AMD': []}\n",
      "{'GME': [], 'Gamestop': [], 'SPY': [], 'TWTTR': [], 'Twitter': [], 'TSLA': [], 'Tesla': [], 'AMD': []}\n"
     ]
    }
   ],
   "source": [
    "print(meanDict)\n",
    "print(spreadDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total comments read:  249\n",
      "  Tick  Counts\n",
      "0  GME       1\n"
     ]
    }
   ],
   "source": [
    "output=pd.DataFrame(data={'Tick': tickerlist, 'Counts': sum})\n",
    "print('Total comments read: ',counttotal)\n",
    "print(output[output['Counts']>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Stock Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os, json, csv\n",
    "\n",
    "size = 'compact' # 'full' for complete historical data, 'compact' for most recent 100\n",
    "ticker = ['GME', 'SPY', 'TWTTR', 'TSLA', 'AMD'] # stock tickers to search for\n",
    "datatype = 'csv' # 'json' for JSON output, 'csv' for CSV output\n",
    "\n",
    "for stock in ticker:\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={stock}&outputsize={size}&datatype={datatype}&apikey=QC1C7LRPUTLC597Q'\n",
    "    response = requests.get(url)\n",
    "    #Save CSV to file\n",
    "    with open(f'{stock}.csv', 'wb') as file:\n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>88.05</td>\n",
       "      <td>91.790</td>\n",
       "      <td>85.3800</td>\n",
       "      <td>85.52</td>\n",
       "      <td>82647701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-28</td>\n",
       "      <td>86.67</td>\n",
       "      <td>90.580</td>\n",
       "      <td>84.7800</td>\n",
       "      <td>89.64</td>\n",
       "      <td>91495449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-27</td>\n",
       "      <td>84.25</td>\n",
       "      <td>87.900</td>\n",
       "      <td>84.0200</td>\n",
       "      <td>84.91</td>\n",
       "      <td>83125054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-26</td>\n",
       "      <td>89.74</td>\n",
       "      <td>90.120</td>\n",
       "      <td>85.0800</td>\n",
       "      <td>85.16</td>\n",
       "      <td>87805574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-25</td>\n",
       "      <td>89.86</td>\n",
       "      <td>91.370</td>\n",
       "      <td>88.6100</td>\n",
       "      <td>90.69</td>\n",
       "      <td>93481042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2021-12-13</td>\n",
       "      <td>138.25</td>\n",
       "      <td>139.400</td>\n",
       "      <td>133.4150</td>\n",
       "      <td>133.80</td>\n",
       "      <td>42173963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>141.29</td>\n",
       "      <td>141.365</td>\n",
       "      <td>135.8200</td>\n",
       "      <td>138.55</td>\n",
       "      <td>42224275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2021-12-09</td>\n",
       "      <td>145.16</td>\n",
       "      <td>146.690</td>\n",
       "      <td>137.8000</td>\n",
       "      <td>138.10</td>\n",
       "      <td>53019926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2021-12-08</td>\n",
       "      <td>144.96</td>\n",
       "      <td>147.040</td>\n",
       "      <td>142.7000</td>\n",
       "      <td>145.24</td>\n",
       "      <td>40977478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>143.90</td>\n",
       "      <td>145.760</td>\n",
       "      <td>141.0001</td>\n",
       "      <td>144.85</td>\n",
       "      <td>53359432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     timestamp    open     high       low   close    volume\n",
       "0   2022-04-29   88.05   91.790   85.3800   85.52  82647701\n",
       "1   2022-04-28   86.67   90.580   84.7800   89.64  91495449\n",
       "2   2022-04-27   84.25   87.900   84.0200   84.91  83125054\n",
       "3   2022-04-26   89.74   90.120   85.0800   85.16  87805574\n",
       "4   2022-04-25   89.86   91.370   88.6100   90.69  93481042\n",
       "..         ...     ...      ...       ...     ...       ...\n",
       "95  2021-12-13  138.25  139.400  133.4150  133.80  42173963\n",
       "96  2021-12-10  141.29  141.365  135.8200  138.55  42224275\n",
       "97  2021-12-09  145.16  146.690  137.8000  138.10  53019926\n",
       "98  2021-12-08  144.96  147.040  142.7000  145.24  40977478\n",
       "99  2021-12-07  143.90  145.760  141.0001  144.85  53359432\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amd_data = pd.read_csv(\"AMD.csv\")\n",
    "amd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get avg, spread, median of sentiment of comments in any given period\n",
    "    compare this with the performance of the stock\n",
    "\n",
    "model:\n",
    "    based on last x days of reddit comments, what is the price going to be?\n",
    "    take data from x days, put it all into one vector, and predict from this\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a function to return all comments that mention a stock based on a given date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import requests\n",
    "import itertools\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def make_request(uri, max_retries = 5):\n",
    "    \"\"\"\n",
    "    Function taken from medium article:\n",
    "    https://medium.com/@pasdan/how-to-scrap-reddit-using-pushshift-io-via-python-a3ebcc9b83f4\n",
    "    \"\"\"\n",
    "    def fire_away(uri):\n",
    "        response = requests.get(uri)\n",
    "        assert response.status_code == 200\n",
    "        return json.loads(response.content)\n",
    "    current_tries = 1\n",
    "    while current_tries < max_retries:\n",
    "        try:\n",
    "            time.sleep(1)\n",
    "            response = fire_away(uri)\n",
    "            return response\n",
    "        except:\n",
    "            time.sleep(1)\n",
    "            current_tries += 1\n",
    "    return fire_away(uri)\n",
    "\n",
    "def get_intervals(startPOSTIX, endPOSTIX, daysInInterval = 1):\n",
    "    \"\"\"\n",
    "    get_intervals goes day by day through the start and end dates, returning that day's POSTIX\n",
    "    \"\"\"\n",
    "    # 86,400 seconds in a day:\n",
    "    period = (86400 * daysInInterval)\n",
    "    end = startPOSTIX + period\n",
    "    \n",
    "    yield(int(startPOSTIX), int(end))\n",
    "    \n",
    "    padding = 1\n",
    "    while end <= endPOSTIX:\n",
    "        startPOSTIX = end + padding\n",
    "        end = (startPOSTIX - padding) + period\n",
    "        yield int(startPOSTIX), int(end)\n",
    "    \n",
    "    \n",
    "def pull_posts_for(subreddit, start_at, end_at):\n",
    "    \"\"\"\n",
    "    Function taken from medium article:\n",
    "    https://medium.com/@pasdan/how-to-scrap-reddit-using-pushshift-io-via-python-a3ebcc9b83f4\n",
    "    \"\"\"\n",
    "    def map_posts(posts):\n",
    "        return list(map(lambda post: {\n",
    "            'id': post['id'],\n",
    "            'created_utc': post['created_utc'],\n",
    "            'prefix': 't4_'\n",
    "        }, posts))\n",
    "    \n",
    "    SIZE = 500\n",
    "    URI_TEMPLATE = r'https://api.pushshift.io/reddit/search/submission?subreddit={}&after={}&before={}&size={}'\n",
    "    \n",
    "    post_collections = map_posts(\n",
    "        make_request(URI_TEMPLATE.format\n",
    "                     (subreddit, start_at, end_at, SIZE))['data'])\n",
    "    n = len(post_collections)\n",
    "    while n == SIZE:\n",
    "        last = post_collections[-1]\n",
    "        new_start_at = last['created_utc'] - (10)\n",
    "        \n",
    "        more_posts = map_posts( \\\n",
    "            make_request( \\\n",
    "                URI_TEMPLATE.format( \\\n",
    "                    subreddit, new_start_at, end_at, bSIZE))['data'])\n",
    "        \n",
    "        n = len(more_posts)\n",
    "        post_collections.extend(more_posts)\n",
    "    return post_collections\n",
    "\n",
    "def get_comments_by_date (startDate, endDate, subreddit='wallstreetbets'):\n",
    "    \"\"\"\n",
    "    Takes a given time interval and scrapes the given subreddit for all of the comments\n",
    "    that relate to the given ticker name, returning them as an array. Basic structure taken \n",
    "    from medium article.\n",
    "    \n",
    "    THIS CURRENTLY WILL NOT WORK IF GIVEN TODAY'S DATE. IT WILL ATTEMPT TO FETCH TOMORROW'S POSTS FOREVER\n",
    "    \"\"\"\n",
    "    # Converting start and end dates to POSTIX:\n",
    "    startDate = math.floor(startDate.timestamp())\n",
    "    endDate = math.floor(endDate.timestamp())\n",
    "\n",
    "    posts = []\n",
    "    # This loop gets all of the posts in the given timeframe\n",
    "    for interval in get_intervals(startDate, endDate):\n",
    "        print(\"-- Fetching Posts From: \", datetime.fromtimestamp(interval[0]), \" to \", datetime.fromtimestamp(interval[1]))\n",
    "        pulled_posts = pull_posts_for(subreddit, interval[0], interval[1])\n",
    "        posts.extend(pulled_posts)\n",
    "        time.sleep(.100) # So as not to over request reddit\n",
    "\n",
    "    TIMEOUT_SECS = 1\n",
    "    \n",
    "    reddit_posts = []\n",
    "    reddit_comments = {}\n",
    "    reddit_comments[startDate] = []\n",
    "    \n",
    "    # Going through each unique post and comment and adding them to the relevant arrays\n",
    "    #  WARNING: only looking at first 100 posts of each day\n",
    "    for sub_id in np.unique([post['id'] for post in posts])[:100]:\n",
    "        # Only looking at posts with more than 100 upvotes to speed the process up\n",
    "        if reddit.submission(sub_id).ups > 100:\n",
    "            print(\"--- Current Post ID: \", sub_id)\n",
    "            sub = reddit.submission(id=sub_id)\n",
    "            reddit_posts.append(sub)\n",
    "            sub.comments.replace_more(limit=None)\n",
    "            # Looping through each comment:\n",
    "            temp_com_count = 0\n",
    "            for comment in sub.comments.list()[:100]: \n",
    "                temp_com_count += 1\n",
    "                reddit_comments[startDate].append(comment.body)\n",
    "                \n",
    "            print(\"---- Fethced {} comments from post\".format(temp_com_count))\n",
    "#             time.sleep(TIMEOUT_SECS)\n",
    "\n",
    "    return reddit_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jan 11 - Jan 27 2021\n",
    "date_range = []\n",
    "\n",
    "# Filling array with dates (should be 11, 28 for GME Boom)\n",
    "for i in range(11, 28):\n",
    "    date_range.append(datetime(2021, 1, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Fetching Posts From:  2021-01-10 00:00:00  to  2021-01-11 00:00:00\n",
      "-- Fetching Posts From:  2021-01-11 00:00:01  to  2021-01-12 00:00:00\n",
      "--- Current Post ID:  ku2fx9\n",
      "---- Current Comment ID:  gipi7uy\n",
      "---- Current Comment ID:  gipjccd\n",
      "---- Current Comment ID:  giq0m76\n",
      "---- Current Comment ID:  gipjog0\n",
      "---- Current Comment ID:  gipvxwc\n",
      "---- Current Comment ID:  gipxcmx\n",
      "---- Current Comment ID:  giqp8hu\n",
      "---- Current Comment ID:  giptay7\n",
      "---- Current Comment ID:  giq9osz\n",
      "---- Current Comment ID:  giqgosu\n",
      "--- Current Post ID:  ku2hgj\n",
      "---- Current Comment ID:  gipizyq\n",
      "---- Current Comment ID:  gipjqn1\n",
      "---- Current Comment ID:  gipj3xf\n",
      "---- Current Comment ID:  gipo0h2\n",
      "---- Current Comment ID:  gipikpc\n",
      "---- Current Comment ID:  giplbac\n",
      "---- Current Comment ID:  gippzm5\n",
      "---- Current Comment ID:  giq55tw\n",
      "---- Current Comment ID:  gipigw2\n",
      "---- Current Comment ID:  gipjfpl\n",
      "--- Current Post ID:  ku2kna\n",
      "---- Current Comment ID:  gipz0dv\n",
      "---- Current Comment ID:  gipj4d4\n",
      "---- Current Comment ID:  gips1yd\n",
      "---- Current Comment ID:  gipsgzb\n",
      "---- Current Comment ID:  gipiugk\n",
      "---- Current Comment ID:  giqfark\n",
      "---- Current Comment ID:  gipnyak\n",
      "---- Current Comment ID:  gipodre\n",
      "---- Current Comment ID:  gipqqgw\n",
      "---- Current Comment ID:  gitnd8x\n",
      "--- Current Post ID:  ku2ref\n",
      "---- Current Comment ID:  gipncp5\n",
      "---- Current Comment ID:  gipnpit\n",
      "---- Current Comment ID:  gipvygo\n",
      "---- Current Comment ID:  gipk9qk\n",
      "---- Current Comment ID:  gipkcc7\n",
      "---- Current Comment ID:  giporvs\n",
      "---- Current Comment ID:  giqtuul\n",
      "---- Current Comment ID:  gipralb\n",
      "---- Current Comment ID:  gipn3jl\n",
      "---- Current Comment ID:  gipvv2c\n",
      "--- Current Post ID:  ku2ujw\n",
      "---- Current Comment ID:  gipna60\n",
      "---- Current Comment ID:  gipz73f\n",
      "---- Current Comment ID:  gipqrcx\n",
      "---- Current Comment ID:  gips915\n",
      "---- Current Comment ID:  gipw5df\n",
      "---- Current Comment ID:  giptm53\n",
      "---- Current Comment ID:  giplt5z\n",
      "---- Current Comment ID:  giq0svb\n",
      "---- Current Comment ID:  gipr76m\n",
      "---- Current Comment ID:  gippcw8\n",
      "-- Fetching Posts From:  2021-01-11 00:00:00  to  2021-01-12 00:00:00\n",
      "-- Fetching Posts From:  2021-01-12 00:00:01  to  2021-01-13 00:00:00\n",
      "--- Current Post ID:  kupcnj\n",
      "---- Current Comment ID:  git71w8\n",
      "---- Current Comment ID:  git7du9\n",
      "---- Current Comment ID:  git9745\n",
      "---- Current Comment ID:  gitbzx8\n",
      "---- Current Comment ID:  git9eky\n",
      "---- Current Comment ID:  git7b0t\n",
      "---- Current Comment ID:  gitil17\n",
      "---- Current Comment ID:  gitj4mj\n",
      "---- Current Comment ID:  git6zh5\n",
      "---- Current Comment ID:  gitvt21\n",
      "--- Current Post ID:  kuq6q7\n",
      "---- Current Comment ID:  gitk2u0\n",
      "---- Current Comment ID:  giths1s\n",
      "---- Current Comment ID:  gitgp9g\n",
      "---- Current Comment ID:  giu3lw9\n",
      "---- Current Comment ID:  giu3qlz\n",
      "---- Current Comment ID:  gity7wx\n",
      "---- Current Comment ID:  gitw0wo\n",
      "---- Current Comment ID:  gitche6\n",
      "---- Current Comment ID:  gitjy42\n",
      "---- Current Comment ID:  gitkfij\n",
      "--- Current Post ID:  kuqk68\n",
      "---- Current Comment ID:  githl55\n",
      "---- Current Comment ID:  giu5a8d\n",
      "---- Current Comment ID:  gityzo1\n",
      "---- Current Comment ID:  giu0vlw\n",
      "---- Current Comment ID:  gituudv\n",
      "---- Current Comment ID:  giu9rvh\n",
      "---- Current Comment ID:  giu3v5v\n",
      "---- Current Comment ID:  gitk3xh\n",
      "---- Current Comment ID:  gitgv5p\n",
      "---- Current Comment ID:  giu4n89\n",
      "-- Fetching Posts From:  2021-01-12 00:00:00  to  2021-01-13 00:00:00\n",
      "-- Fetching Posts From:  2021-01-13 00:00:01  to  2021-01-14 00:00:00\n",
      "--- Current Post ID:  kvellp\n",
      "---- Current Comment ID:  gixt4kw\n",
      "---- Current Comment ID:  gixtbkp\n",
      "---- Current Comment ID:  gixt5mu\n",
      "---- Current Comment ID:  gixtu31\n",
      "---- Current Comment ID:  gixteqm\n",
      "---- Current Comment ID:  gixt0ur\n",
      "---- Current Comment ID:  giy01wi\n",
      "---- Current Comment ID:  giy3yyy\n",
      "---- Current Comment ID:  gixv3w4\n",
      "---- Current Comment ID:  gixtq84\n",
      "--- Current Post ID:  kvf7r1\n",
      "---- Current Comment ID:  gixxlmv\n",
      "---- Current Comment ID:  gixwxe6\n",
      "---- Current Comment ID:  giy6gyc\n",
      "---- Current Comment ID:  gixxr7i\n",
      "---- Current Comment ID:  giy8tjq\n",
      "---- Current Comment ID:  gixyaxk\n",
      "---- Current Comment ID:  giy8unl\n",
      "---- Current Comment ID:  giypiit\n",
      "---- Current Comment ID:  giywojl\n",
      "---- Current Comment ID:  giyzqp9\n",
      "--- Current Post ID:  kvf9od\n",
      "---- Current Comment ID:  gixxbm4\n",
      "---- Current Comment ID:  giy0wtq\n",
      "---- Current Comment ID:  gixxqfc\n",
      "---- Current Comment ID:  giy7f7w\n",
      "---- Current Comment ID:  giy1dh2\n",
      "---- Current Comment ID:  giy2qb1\n",
      "---- Current Comment ID:  giyfzrv\n",
      "---- Current Comment ID:  giz6yi2\n",
      "---- Current Comment ID:  gl95k4r\n",
      "---- Current Comment ID:  giyjl9o\n",
      "--- Current Post ID:  kvfd4i\n",
      "---- Current Comment ID:  giy0qnx\n",
      "---- Current Comment ID:  gixxmrp\n",
      "---- Current Comment ID:  giy1wuv\n",
      "---- Current Comment ID:  gixxq1v\n",
      "---- Current Comment ID:  gixz2nl\n",
      "---- Current Comment ID:  giyo3ab\n",
      "---- Current Comment ID:  giyafr2\n",
      "---- Current Comment ID:  gixzbs6\n",
      "---- Current Comment ID:  giy5b4b\n",
      "---- Current Comment ID:  giy0c8f\n",
      "--- Current Post ID:  kvfgn2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8688/3448900850.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mend_day\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mday\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mstart_day\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mday\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtemp_all_coms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_comments_by_date\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_day\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_day\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mall_comments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_all_coms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8688/1353675359.py\u001b[0m in \u001b[0;36mget_comments_by_date\u001b[1;34m(startDate, endDate, subreddit)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0msub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreddit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmission\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msub_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mreddit_posts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0msub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace_more\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[1;31m# Looping through each comment:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcomment\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\praw\\models\\comment_forest.py\u001b[0m in \u001b[0;36mreplace_more\u001b[1;34m(self, limit, threshold)\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0mnew_comments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mremaining\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\praw\\models\\reddit\\more.py\u001b[0m in \u001b[0;36mcomments\u001b[1;34m(self, update)\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;34m\"sort\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmission\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomment_sort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             }\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_comments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reddit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAPI_PATH\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"morechildren\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mcomment\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_comments\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\praw\\reddit.py\u001b[0m in \u001b[0;36mpost\u001b[1;34m(self, path, data, files, params, json)\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mattempts\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 793\u001b[1;33m                 return self._objectify_request(\n\u001b[0m\u001b[0;32m    794\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m                     \u001b[0mfiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\praw\\reddit.py\u001b[0m in \u001b[0;36m_objectify_request\u001b[1;34m(self, data, files, json, method, params, path)\u001b[0m\n\u001b[0;32m    694\u001b[0m         \"\"\"\n\u001b[0;32m    695\u001b[0m         return self._objector.objectify(\n\u001b[1;32m--> 696\u001b[1;33m             self.request(\n\u001b[0m\u001b[0;32m    697\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[0mfiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\praw\\reddit.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, path, params, data, files, json)\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mClientException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At most one of `data` and `json` is supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m             return self._core.request(\n\u001b[0m\u001b[0;32m    886\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\prawcore\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, path, data, files, json, params, timeout)\u001b[0m\n\u001b[0;32m    328\u001b[0m             \u001b[0mjson\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"api_type\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"json\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murljoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_requestor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moauth_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         return self._request_with_retries(\n\u001b[0m\u001b[0;32m    331\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[0mfiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\prawcore\\sessions.py\u001b[0m in \u001b[0;36m_request_with_retries\u001b[1;34m(self, data, files, json, method, params, timeout, url, retry_strategy_state)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[0mretry_strategy_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         response, saved_exception = self._make_request(\n\u001b[0m\u001b[0;32m    229\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\prawcore\\sessions.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, data, files, json, method, params, retry_strategy_state, timeout, url)\u001b[0m\n\u001b[0;32m    183\u001b[0m     ):\n\u001b[0;32m    184\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             response = self._rate_limiter.call(\n\u001b[0m\u001b[0;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_requestor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_header_callback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\prawcore\\rate_limit.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, request_function, set_header_callback, *args, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \"\"\"\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"headers\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset_header_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\prawcore\\rate_limit.py\u001b[0m in \u001b[0;36mdelay\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"Sleeping: {sleep_seconds:0.2f} seconds prior to call\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msleep_seconds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse_headers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_comments = {}\n",
    "for day in date_range:\n",
    "    end_day = day\n",
    "    start_day = day - timedelta(days=1)\n",
    "    temp_all_coms = get_comments_by_date(start_day, end_day)\n",
    "    all_comments.update(temp_all_coms)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Fetching Posts From:  2021-01-12 00:00:00  to  2021-01-13 00:00:00\n",
      "-- Fetching Posts From:  2021-01-13 00:00:01  to  2021-01-14 00:00:00\n",
      "--- Current Post ID:  kvellp\n",
      "---- Current Comment ID:  gixt4kw\n",
      "---- Current Comment ID:  gixtbkp\n",
      "---- Current Comment ID:  gixt5mu\n",
      "---- Current Comment ID:  gixtu31\n",
      "---- Current Comment ID:  gixteqm\n",
      "---- Current Comment ID:  gixt0ur\n",
      "---- Current Comment ID:  giy01wi\n",
      "---- Current Comment ID:  giy3yyy\n",
      "---- Current Comment ID:  gixv3w4\n",
      "---- Current Comment ID:  gixtq84\n"
     ]
    }
   ],
   "source": [
    "# Change this to the next day:\n",
    "day = date_range[2]\n",
    "end_day = day\n",
    "start_day = day - timedelta(days=1)\n",
    "temp_all_coms = get_comments_by_date(start_day, end_day)\n",
    "all_comments.update(temp_all_coms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1610233200, 1610319600])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_comments.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickerlist = ['GME', 'Gamestop', 'SPY', 'TWTTR', 'Twitter', 'TSLA', 'Tesla', 'AMD']\n",
    "ticker_dict = {}\n",
    "\n",
    "# Filling ticker_dict with empty dictionaries\n",
    "for tick in tickerlist:\n",
    "    ticker_dict[tick] = {}\n",
    "\n",
    "    # Filling the dictionaries in ticker_dict with empty lists\n",
    "for tick in tickerlist:\n",
    "    for key in all_comments.keys():\n",
    "        ticker_dict[tick][key] = []\n",
    "        \n",
    "# Adding the comments to their ticker and date\n",
    "for tick in tickerlist:\n",
    "    for key in all_comments.keys():\n",
    "        for com in all_comments[key]:\n",
    "            if tick in com:\n",
    "                ticker_dict[tick][key].append(com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1610233200, 1610319600, 1610406000, 1610492400, 1610578800, 1610665200, 1610751600, 1610838000, 1610924400, 1611010800, 1611097200, 1611183600, 1611270000, 1611356400, 1611442800, 1611529200, 1611615600])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_comments.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GME': {1610233200: [],\n",
       "  1610319600: ['I will become a millionaire by the end of 2021. I will escape the rat race. And I will lose it all on a YOLO GME put \\n\\n&#x200B;\\n\\np: $CMC 88 contracts 26.51 call'],\n",
       "  1610406000: [],\n",
       "  1610492400: [],\n",
       "  1610578800: [\"My broker can't provide me with certain stocks, GME being one of them and I want to cry\",\n",
       "   'So I just joined this sub today, and have seen nothing but GME posts. What happened?\\n\\nEdit: besides GME shooting up. Why did everyone decide to Yolo it? Was there some sort of market indicator?'],\n",
       "  1610665200: [],\n",
       "  1610751600: ['Iâ€™ll FUCKING DO IT AGAIN!!! ðŸš€ðŸš€ðŸ“ˆGME for lifeðŸš€ðŸš€ðŸš€'],\n",
       "  1610838000: [],\n",
       "  1610924400: [],\n",
       "  1611010800: [],\n",
       "  1611097200: [],\n",
       "  1611183600: [],\n",
       "  1611270000: [],\n",
       "  1611356400: [],\n",
       "  1611442800: [],\n",
       "  1611529200: [],\n",
       "  1611615600: []},\n",
       " 'Gamestop': {1610233200: [],\n",
       "  1610319600: [],\n",
       "  1610406000: [],\n",
       "  1610492400: [],\n",
       "  1610578800: [],\n",
       "  1610665200: [],\n",
       "  1610751600: [],\n",
       "  1610838000: [],\n",
       "  1610924400: [],\n",
       "  1611010800: [],\n",
       "  1611097200: [],\n",
       "  1611183600: [],\n",
       "  1611270000: [],\n",
       "  1611356400: [],\n",
       "  1611442800: [],\n",
       "  1611529200: [],\n",
       "  1611615600: []},\n",
       " 'SPY': {1610233200: [],\n",
       "  1610319600: [],\n",
       "  1610406000: [],\n",
       "  1610492400: [],\n",
       "  1610578800: [],\n",
       "  1610665200: [],\n",
       "  1610751600: [],\n",
       "  1610838000: [],\n",
       "  1610924400: [],\n",
       "  1611010800: [],\n",
       "  1611097200: [],\n",
       "  1611183600: [],\n",
       "  1611270000: [],\n",
       "  1611356400: [],\n",
       "  1611442800: [],\n",
       "  1611529200: [],\n",
       "  1611615600: []},\n",
       " 'TWTTR': {1610233200: [],\n",
       "  1610319600: [],\n",
       "  1610406000: [],\n",
       "  1610492400: [],\n",
       "  1610578800: [],\n",
       "  1610665200: [],\n",
       "  1610751600: [],\n",
       "  1610838000: [],\n",
       "  1610924400: [],\n",
       "  1611010800: [],\n",
       "  1611097200: [],\n",
       "  1611183600: [],\n",
       "  1611270000: [],\n",
       "  1611356400: [],\n",
       "  1611442800: [],\n",
       "  1611529200: [],\n",
       "  1611615600: []},\n",
       " 'Twitter': {1610233200: [],\n",
       "  1610319600: [],\n",
       "  1610406000: [],\n",
       "  1610492400: [],\n",
       "  1610578800: [],\n",
       "  1610665200: [],\n",
       "  1610751600: [],\n",
       "  1610838000: [],\n",
       "  1610924400: [],\n",
       "  1611010800: [],\n",
       "  1611097200: [],\n",
       "  1611183600: [],\n",
       "  1611270000: [],\n",
       "  1611356400: [],\n",
       "  1611442800: [],\n",
       "  1611529200: [],\n",
       "  1611615600: []},\n",
       " 'TSLA': {1610233200: [],\n",
       "  1610319600: [],\n",
       "  1610406000: [],\n",
       "  1610492400: [],\n",
       "  1610578800: [],\n",
       "  1610665200: [],\n",
       "  1610751600: [],\n",
       "  1610838000: [],\n",
       "  1610924400: [],\n",
       "  1611010800: [],\n",
       "  1611097200: [],\n",
       "  1611183600: [],\n",
       "  1611270000: [],\n",
       "  1611356400: [],\n",
       "  1611442800: [],\n",
       "  1611529200: [],\n",
       "  1611615600: []},\n",
       " 'Tesla': {1610233200: [],\n",
       "  1610319600: [],\n",
       "  1610406000: [],\n",
       "  1610492400: [],\n",
       "  1610578800: [],\n",
       "  1610665200: [],\n",
       "  1610751600: [],\n",
       "  1610838000: [],\n",
       "  1610924400: [],\n",
       "  1611010800: [],\n",
       "  1611097200: [],\n",
       "  1611183600: [],\n",
       "  1611270000: [],\n",
       "  1611356400: [],\n",
       "  1611442800: [],\n",
       "  1611529200: [],\n",
       "  1611615600: []},\n",
       " 'AMD': {1610233200: [],\n",
       "  1610319600: [],\n",
       "  1610406000: [],\n",
       "  1610492400: [],\n",
       "  1610578800: [],\n",
       "  1610665200: [],\n",
       "  1610751600: [],\n",
       "  1610838000: [],\n",
       "  1610924400: [],\n",
       "  1611010800: [],\n",
       "  1611097200: [],\n",
       "  1611183600: [],\n",
       "  1611270000: [],\n",
       "  1611356400: [],\n",
       "  1611442800: [],\n",
       "  1611529200: [],\n",
       "  1611615600: []}}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the Comments Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_df = pd.DataFrame()\n",
    "tickerlist = ['GME', 'Gamestop', 'SPY', 'TWTTR', 'Twitter', 'TSLA', 'Tesla', 'AMD']\n",
    "# all_comments = get_comments_by_date(start, end)\n",
    "ticker_dates_dict = {}\n",
    "\n",
    "for tick in tickerlist:\n",
    "    ticker_dates_dict[tick] = pd.DataFrame()\n",
    "\n",
    "# Dates begin yesterday through today:\n",
    "end_day = datetime.today() # End day is today\n",
    "start_day = end_day - timedelta(days=7) # Start day is one week ag\n",
    "\n",
    "# Running for the past week:\n",
    "for tick in tickerlist:\n",
    "    for i in range(0, 7):\n",
    "        end_day = datetime.today() - timedelta(days=i)\n",
    "        start_day = datetime.today() - timedelta(days=i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_dates_dict['SPY']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
