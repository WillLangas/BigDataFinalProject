{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Reddit Comment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from praw.models import MoreComments\n",
    "import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=\"p1dG7hgoowK4BSlUdar1WQ\",\n",
    "    client_secret=\"pEePtSnw7KMDZi6fCzkKaOth_pgKpQ\",\n",
    "    password=\"outdoortuesday\",\n",
    "    user_agent=\"Big Data by u/DISWillJayminMaya \",\n",
    "    username=\"DISWillJayminMaya \",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickerlist = ['GME', 'Gamestop', 'SPY', 'TWTTR', 'Twitter', 'TSLA', 'Tesla', 'AMD']\n",
    "subreddit = reddit.subreddit('wallstreetbets')\n",
    "\n",
    "hot = subreddit.hot(limit=25) # getting first 15 posts in the 'hot' section of the subreddit\n",
    "sum = [0] * len(tickerlist) # our output array\n",
    "counttotal = 0 # total number of comment read\n",
    "submissions_counter = 0\n",
    "\n",
    "rel_comments = [] # List of comments that are relevant to the ticker list items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for fetching the comments and the amount of time each ticker is mentioned\n",
    "for submissions in hot:\n",
    "    if not submissions.stickied:\n",
    "        submissions_counter+=1\n",
    "        if submissions_counter > 5:\n",
    "            comments = submissions.comments\n",
    "            for comment in comments:\n",
    "                if isinstance(comment, MoreComments):\n",
    "                    continue\n",
    "                counttotal+=1\n",
    "                for i, ticker in enumerate(tickerlist):\n",
    "                    if ticker in comment.body:\n",
    "                        rel_comments.append(comment.body)\n",
    "                        sum[i]=sum[i]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total comments read:  1203\n",
      "      Tick  Counts\n",
      "0      GME       1\n",
      "2      SPY       4\n",
      "4  Twitter      50\n",
      "5     TSLA       2\n",
      "6    Tesla      13\n"
     ]
    }
   ],
   "source": [
    "output=pd.DataFrame(data={'Tick': tickerlist, 'Counts': sum})\n",
    "print('Total comments read: ',counttotal)\n",
    "print(output[output['Counts']>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Stock Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os, json, csv\n",
    "\n",
    "size = 'compact' # 'full' for complete historical data, 'compact' for most recent 100\n",
    "ticker = ['GME', 'SPY', 'TWTTR', 'TSLA', 'AMD'] # stock tickers to search for\n",
    "datatype = 'csv' # 'json' for JSON output, 'csv' for CSV output\n",
    "\n",
    "for stock in ticker:\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={stock}&outputsize={size}&datatype={datatype}&apikey=QC1C7LRPUTLC597Q'\n",
    "    response = requests.get(url)\n",
    "    #Save CSV to file\n",
    "    with open(f'{stock}.csv', 'wb') as file:\n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-25</td>\n",
       "      <td>89.860</td>\n",
       "      <td>91.37</td>\n",
       "      <td>88.6100</td>\n",
       "      <td>90.69</td>\n",
       "      <td>93481042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-22</td>\n",
       "      <td>90.030</td>\n",
       "      <td>91.46</td>\n",
       "      <td>87.9350</td>\n",
       "      <td>88.14</td>\n",
       "      <td>75017652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>95.160</td>\n",
       "      <td>96.23</td>\n",
       "      <td>89.2400</td>\n",
       "      <td>89.85</td>\n",
       "      <td>76680635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-20</td>\n",
       "      <td>97.840</td>\n",
       "      <td>97.91</td>\n",
       "      <td>93.2000</td>\n",
       "      <td>94.02</td>\n",
       "      <td>62322274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>93.385</td>\n",
       "      <td>97.07</td>\n",
       "      <td>92.8400</td>\n",
       "      <td>96.93</td>\n",
       "      <td>77069496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>143.900</td>\n",
       "      <td>145.76</td>\n",
       "      <td>141.0001</td>\n",
       "      <td>144.85</td>\n",
       "      <td>53359432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>141.135</td>\n",
       "      <td>141.31</td>\n",
       "      <td>134.2000</td>\n",
       "      <td>139.06</td>\n",
       "      <td>66776493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>151.645</td>\n",
       "      <td>152.38</td>\n",
       "      <td>140.7200</td>\n",
       "      <td>144.01</td>\n",
       "      <td>65910028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2021-12-02</td>\n",
       "      <td>147.675</td>\n",
       "      <td>152.53</td>\n",
       "      <td>146.4700</td>\n",
       "      <td>150.68</td>\n",
       "      <td>56161216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>160.370</td>\n",
       "      <td>160.88</td>\n",
       "      <td>148.9200</td>\n",
       "      <td>149.11</td>\n",
       "      <td>64185119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     timestamp     open    high       low   close    volume\n",
       "0   2022-04-25   89.860   91.37   88.6100   90.69  93481042\n",
       "1   2022-04-22   90.030   91.46   87.9350   88.14  75017652\n",
       "2   2022-04-21   95.160   96.23   89.2400   89.85  76680635\n",
       "3   2022-04-20   97.840   97.91   93.2000   94.02  62322274\n",
       "4   2022-04-19   93.385   97.07   92.8400   96.93  77069496\n",
       "..         ...      ...     ...       ...     ...       ...\n",
       "95  2021-12-07  143.900  145.76  141.0001  144.85  53359432\n",
       "96  2021-12-06  141.135  141.31  134.2000  139.06  66776493\n",
       "97  2021-12-03  151.645  152.38  140.7200  144.01  65910028\n",
       "98  2021-12-02  147.675  152.53  146.4700  150.68  56161216\n",
       "99  2021-12-01  160.370  160.88  148.9200  149.11  64185119\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amd_data = pd.read_csv(\"AMD.csv\")\n",
    "amd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get avg, spread, median of sentiment of comments in any given period\n",
    "    compare this with the performance of the stock\n",
    "\n",
    "model:\n",
    "    based on last x days of reddit comments, what is the price going to be?\n",
    "    take data from x days, put it all into one vector, and predict from this\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://medium.com/@pasdan/how-to-scrap-reddit-using-pushshift-io-via-python-a3ebcc9b83f4\n",
    "import math\n",
    "import json\n",
    "import requests\n",
    "import itertools\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def make_request(uri, max_retries = 5):\n",
    "    def fire_away(uri):\n",
    "        response = requests.get(uri)\n",
    "        assert response.status_code == 200\n",
    "        return json.loads(response.content)\n",
    "    current_tries = 1\n",
    "    while current_tries < max_retries:\n",
    "        try:\n",
    "            time.sleep(1)\n",
    "            response = fire_away(uri)\n",
    "            return response\n",
    "        except:\n",
    "            time.sleep(1)\n",
    "            current_tries += 1\n",
    "    return fire_away(uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_posts_for(subreddit, start_at, end_at):\n",
    "    \n",
    "    def map_posts(posts):\n",
    "        return list(map(lambda post: {\n",
    "            'id': post['id'],\n",
    "            'created_utc': post['created_utc'],\n",
    "            'prefix': 't4_'\n",
    "        }, posts))\n",
    "    \n",
    "    SIZE = 500\n",
    "    URI_TEMPLATE = r'https://api.pushshift.io/reddit/search/submission?subreddit={}&after={}&before={}&size={}'\n",
    "    \n",
    "    post_collections = map_posts(\n",
    "        make_request(URI_TEMPLATE.format\n",
    "                     (subreddit, start_at, end_at, SIZE))['data'])\n",
    "    n = len(post_collections)\n",
    "    while n == SIZE:\n",
    "        last = post_collections[-1]\n",
    "        new_start_at = last['created_utc'] - (10)\n",
    "        \n",
    "        more_posts = map_posts( \\\n",
    "            make_request( \\\n",
    "                URI_TEMPLATE.format( \\\n",
    "                    subreddit, new_start_at, end_at, bSIZE))['data'])\n",
    "        \n",
    "        n = len(more_posts)\n",
    "        post_collections.extend(more_posts)\n",
    "    return post_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "subreddit = 'wallstreetbets'\n",
    "end_at = math.ceil(datetime.utcnow().timestamp())\n",
    "start_at = math.floor((datetime.utcnow() - timedelta(days=365)).timestamp())\n",
    "posts = pull_posts_for(subreddit, start_at, end_at)\n",
    "## ~ 4314\n",
    "print(len(posts))\n",
    "## ~ 4306\n",
    "print(len(np.unique([ post['id'] for post in posts ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_me_intervals(start_at, number_of_days_per_interval = 3):\n",
    "    \n",
    "    end_at = math.ceil(datetime.utcnow().timestamp())\n",
    "        \n",
    "    ## 1 day = 86400,\n",
    "    period = (86400 * number_of_days_per_interval)\n",
    "    end = start_at + period\n",
    "    yield (int(start_at), int(end))\n",
    "    padding = 1\n",
    "    while end <= end_at:\n",
    "        start_at = end + padding\n",
    "        end = (start_at - padding) + period\n",
    "        yield int(start_at), int(end)\n",
    "## test out the solution,\n",
    "start_at = math.floor(\\\n",
    "     (datetime.utcnow() - timedelta(days=365)).timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where the date is added. Could just make this a function and enter in dates and use that for indexing in the dataframes\n",
    "def get_comments(start_date=(datetime.utcnow() - timedelta(days=7)), end_date=datetime.utcnow()):\n",
    "    subreddit = 'wallstreetbets'\n",
    "    start_at = math.floor(start_date.timestamp())\n",
    "    posts = []\n",
    "    for interval in give_me_intervals(start_at, 7):\n",
    "        pulled_posts = pull_posts_for(\n",
    "            subreddit, interval[0], interval[1])\n",
    "\n",
    "        posts.extend(pulled_posts)\n",
    "        time.sleep(.500)\n",
    "        \n",
    "    TIMEOUT_AFTER_COMMENT_IN_SECS = .350\n",
    "    posts_from_reddit = []\n",
    "    comments_from_reddit = []\n",
    "    for submission_id in np.unique([ post['id'] for post in posts ]):\n",
    "        submission = reddit.submission(id=submission_id)\n",
    "        posts_from_reddit.append(submission)\n",
    "        submission.comments.replace_more(limit=None)\n",
    "        for comment in submission.comments.list():\n",
    "            comments_from_reddit.append(comment)\n",
    "\n",
    "            if TIMEOUT_AFTER_COMMENT_IN_SECS > 0:\n",
    "                time.sleep(TIMEOUT_AFTER_COMMENT_IN_SECS)\n",
    "    \n",
    "    return comments_from_reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_comments()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
